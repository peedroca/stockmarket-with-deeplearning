{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vamos construir nosso modelo de previs√£o baseando-se em um LSTM AutoEncoder\n",
    "\n",
    "- Autoencoders are a type of self-supervised learning model that can learn a compressed representation of input data.\n",
    "- LSTM Autoencoders can learn a compressed representation of sequence data and have been used on video, text, audio, and time series sequence data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4735, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./bases/treino.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.08897853, 1.07980466, 1.08635736, 1.09815192, 1.06932187,\n",
       "       1.0614593 , 1.06276929, 1.0811162 , 1.06670117, 1.0811162 ,\n",
       "       1.0247668 , 1.04835486, 1.0339402 , 1.02345657])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = ['Past_1_Days_Close',\n",
    "'Past_2_Days_Close',\n",
    "'Past_3_Days_Close',\n",
    "'Past_4_Days_Close',\n",
    "'Past_5_Days_Close',\n",
    "'Past_6_Days_Close',\n",
    "'Past_7_Days_Close',\n",
    "'Past_8_Days_Close',\n",
    "'Past_9_Days_Close',\n",
    "'Past_10_Days_Close',\n",
    "'Past_11_Days_Close',\n",
    "'Past_12_Days_Close',\n",
    "'Past_13_Days_Close',\n",
    "'Past_14_Days_Close']\n",
    "\n",
    "y_cols = ['Past_2_Days_Close',\n",
    "'Past_3_Days_Close',\n",
    "'Past_4_Days_Close',\n",
    "'Past_5_Days_Close',\n",
    "'Past_6_Days_Close',\n",
    "'Past_7_Days_Close',\n",
    "'Past_8_Days_Close',\n",
    "'Past_9_Days_Close',\n",
    "'Past_10_Days_Close',\n",
    "'Past_11_Days_Close',\n",
    "'Past_12_Days_Close',\n",
    "'Past_13_Days_Close',\n",
    "'Past_14_Days_Close',\n",
    "'Past_15_Days_Close']\n",
    "\n",
    "df[x_cols].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(df[x_cols], df[y_cols], shuffle = False, test_size=0.1)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_temp, y_temp, shuffle = False, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.shape[1]\n",
    "\n",
    "scaler_rate = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler_rate.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler_rate.transform(X_train).reshape(-1, features, 1)\n",
    "X_validation_scaled = scaler_rate.transform(X_validation).reshape(-1, features, 1)\n",
    "X_test_scaled = scaler_rate.transform(X_test).reshape(-1, features, 1)\n",
    "\n",
    "scaler_trend = MinMaxScaler(feature_range=(-1,1))\n",
    "scaler_trend.fit(y_train)\n",
    "\n",
    "y_train_scaled = scaler_trend.transform(y_train).reshape(-1, features, 1)\n",
    "y_validation_scaled = scaler_trend.transform(y_validation).reshape(-1, features, 1)\n",
    "y_test_scaled = scaler_trend.transform(y_test).reshape(-1, features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (3408, 14, 1)\n",
      "Validation (853, 14, 1)\n",
      "Test (474, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train', X_train_scaled.shape)\n",
    "print('Validation', X_validation_scaled.shape)\n",
    "print('Test', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(features, 1)))\n",
    "model.add(RepeatVector(features))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3408/3408 [==============================] - 37s 11ms/step - loss: 0.0066 - val_loss: 0.1275 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "3408/3408 [==============================] - 38s 11ms/step - loss: 0.0093 - val_loss: 0.1303 - lr: 9.0000e-04\n",
      "Epoch 3/300\n",
      "3408/3408 [==============================] - 36s 10ms/step - loss: 0.0045 - val_loss: 0.1242 - lr: 8.1000e-04\n",
      "Epoch 4/300\n",
      "3408/3408 [==============================] - 34s 10ms/step - loss: 0.0042 - val_loss: 0.1162 - lr: 7.2900e-04\n",
      "Epoch 5/300\n",
      "3408/3408 [==============================] - 38s 11ms/step - loss: 0.0047 - val_loss: 0.1100 - lr: 6.5610e-04\n",
      "Epoch 6/300\n",
      "3408/3408 [==============================] - 38s 11ms/step - loss: 0.0033 - val_loss: 0.0926 - lr: 5.9049e-04\n",
      "Epoch 7/300\n",
      "3408/3408 [==============================] - 33s 10ms/step - loss: 0.0023 - val_loss: 0.0735 - lr: 5.3144e-04\n",
      "Epoch 8/300\n",
      "3408/3408 [==============================] - 38s 11ms/step - loss: 0.0017 - val_loss: 0.0819 - lr: 4.7830e-04\n",
      "Epoch 9/300\n",
      "3408/3408 [==============================] - 38s 11ms/step - loss: 0.0019 - val_loss: 0.0750 - lr: 4.3047e-04\n",
      "Epoch 10/300\n",
      "3408/3408 [==============================] - 35s 10ms/step - loss: 0.0013 - val_loss: 0.0799 - lr: 3.8742e-04\n",
      "Epoch 11/300\n",
      "3408/3408 [==============================] - 33s 10ms/step - loss: 0.0015 - val_loss: 0.0670 - lr: 3.4868e-04\n",
      "Epoch 12/300\n",
      "3408/3408 [==============================] - 35s 10ms/step - loss: 0.0012 - val_loss: 0.0616 - lr: 3.1381e-04\n",
      "Epoch 13/300\n",
      "3408/3408 [==============================] - 38s 11ms/step - loss: 0.0011 - val_loss: 0.0471 - lr: 2.8243e-04\n",
      "Epoch 14/300\n",
      "3408/3408 [==============================] - 36s 11ms/step - loss: 9.4920e-04 - val_loss: 0.0360 - lr: 2.5419e-04\n",
      "Epoch 15/300\n",
      "3408/3408 [==============================] - 33s 10ms/step - loss: 8.3863e-04 - val_loss: 0.0321 - lr: 2.2877e-04\n",
      "Epoch 16/300\n",
      "3408/3408 [==============================] - 37s 11ms/step - loss: 7.8220e-04 - val_loss: 0.0293 - lr: 2.0589e-04\n",
      "Epoch 17/300\n",
      "3408/3408 [==============================] - 37s 11ms/step - loss: 7.6001e-04 - val_loss: 0.0280 - lr: 1.8530e-04\n",
      "Epoch 18/300\n",
      "3408/3408 [==============================] - 35s 10ms/step - loss: 6.8160e-04 - val_loss: 0.0274 - lr: 1.6677e-04\n",
      "Epoch 19/300\n",
      "3408/3408 [==============================] - 36s 11ms/step - loss: 6.5199e-04 - val_loss: 0.0287 - lr: 1.5009e-04\n",
      "Epoch 20/300\n",
      "3408/3408 [==============================] - 37s 11ms/step - loss: 5.9802e-04 - val_loss: 0.0297 - lr: 1.3509e-04\n",
      "Epoch 21/300\n",
      "3408/3408 [==============================] - 37s 11ms/step - loss: 5.6253e-04 - val_loss: 0.0322 - lr: 1.2158e-04\n",
      "Epoch 22/300\n",
      "3408/3408 [==============================] - 35s 10ms/step - loss: 5.4188e-04 - val_loss: 0.0356 - lr: 1.0942e-04\n",
      "Epoch 23/300\n",
      "3408/3408 [==============================] - 37s 11ms/step - loss: 5.2064e-04 - val_loss: 0.0386 - lr: 9.8477e-05\n",
      "Epoch 24/300\n",
      "3408/3408 [==============================] - 41s 12ms/step - loss: 5.1031e-04 - val_loss: 0.0415 - lr: 8.8629e-05\n",
      "Epoch 25/300\n",
      "3408/3408 [==============================] - 36s 11ms/step - loss: 5.0443e-04 - val_loss: 0.0454 - lr: 7.9766e-05\n",
      "Epoch 26/300\n",
      "3408/3408 [==============================] - 42s 12ms/step - loss: 4.9585e-04 - val_loss: 0.0498 - lr: 7.1790e-05\n",
      "Epoch 27/300\n",
      "3408/3408 [==============================] - 39s 11ms/step - loss: 4.9131e-04 - val_loss: 0.0537 - lr: 6.4611e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb4cf022650>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(patience=10, verbose=0, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
    "red_lr = LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "\n",
    "model.fit(\n",
    "    x=X_train_scaled, \n",
    "    y=y_train_scaled, \n",
    "    validation_data=(X_validation_scaled, y_validation_scaled),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    epochs=300, \n",
    "    verbose=1,\n",
    "    callbacks=[es, red_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(474, 14, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(X_test_scaled)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.059635</td>\n",
       "      <td>16.434090</td>\n",
       "      <td>17.890060</td>\n",
       "      <td>18.077581</td>\n",
       "      <td>18.566059</td>\n",
       "      <td>18.906126</td>\n",
       "      <td>19.262169</td>\n",
       "      <td>19.509714</td>\n",
       "      <td>19.836903</td>\n",
       "      <td>19.766409</td>\n",
       "      <td>19.452061</td>\n",
       "      <td>19.202967</td>\n",
       "      <td>18.440727</td>\n",
       "      <td>17.007618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.138468</td>\n",
       "      <td>16.440966</td>\n",
       "      <td>18.026663</td>\n",
       "      <td>18.238346</td>\n",
       "      <td>18.814768</td>\n",
       "      <td>19.224266</td>\n",
       "      <td>19.681057</td>\n",
       "      <td>20.046896</td>\n",
       "      <td>20.492931</td>\n",
       "      <td>20.461088</td>\n",
       "      <td>19.950544</td>\n",
       "      <td>19.136570</td>\n",
       "      <td>17.527023</td>\n",
       "      <td>15.430189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.222895</td>\n",
       "      <td>16.457323</td>\n",
       "      <td>18.130072</td>\n",
       "      <td>18.357611</td>\n",
       "      <td>19.001923</td>\n",
       "      <td>19.481209</td>\n",
       "      <td>20.036549</td>\n",
       "      <td>20.524389</td>\n",
       "      <td>21.095318</td>\n",
       "      <td>21.068941</td>\n",
       "      <td>20.304949</td>\n",
       "      <td>18.939095</td>\n",
       "      <td>16.705061</td>\n",
       "      <td>14.348816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.174421</td>\n",
       "      <td>16.412159</td>\n",
       "      <td>18.144098</td>\n",
       "      <td>18.376959</td>\n",
       "      <td>19.064091</td>\n",
       "      <td>19.589020</td>\n",
       "      <td>20.219782</td>\n",
       "      <td>20.815521</td>\n",
       "      <td>21.543682</td>\n",
       "      <td>21.649441</td>\n",
       "      <td>20.888117</td>\n",
       "      <td>19.331097</td>\n",
       "      <td>16.721163</td>\n",
       "      <td>14.026813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.171404</td>\n",
       "      <td>16.385445</td>\n",
       "      <td>18.210249</td>\n",
       "      <td>18.462320</td>\n",
       "      <td>19.225727</td>\n",
       "      <td>19.843809</td>\n",
       "      <td>20.624874</td>\n",
       "      <td>21.443295</td>\n",
       "      <td>22.440388</td>\n",
       "      <td>22.700556</td>\n",
       "      <td>21.790695</td>\n",
       "      <td>19.643763</td>\n",
       "      <td>16.283575</td>\n",
       "      <td>13.264340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5   \\\n",
       "0  18.059635  16.434090  17.890060  18.077581  18.566059  18.906126   \n",
       "1  18.138468  16.440966  18.026663  18.238346  18.814768  19.224266   \n",
       "2  18.222895  16.457323  18.130072  18.357611  19.001923  19.481209   \n",
       "3  18.174421  16.412159  18.144098  18.376959  19.064091  19.589020   \n",
       "4  18.171404  16.385445  18.210249  18.462320  19.225727  19.843809   \n",
       "\n",
       "          6          7          8          9          10         11  \\\n",
       "0  19.262169  19.509714  19.836903  19.766409  19.452061  19.202967   \n",
       "1  19.681057  20.046896  20.492931  20.461088  19.950544  19.136570   \n",
       "2  20.036549  20.524389  21.095318  21.068941  20.304949  18.939095   \n",
       "3  20.219782  20.815521  21.543682  21.649441  20.888117  19.331097   \n",
       "4  20.624874  21.443295  22.440388  22.700556  21.790695  19.643763   \n",
       "\n",
       "          12         13  \n",
       "0  18.440727  17.007618  \n",
       "1  17.527023  15.430189  \n",
       "2  16.705061  14.348816  \n",
       "3  16.721163  14.026813  \n",
       "4  16.283575  13.264340  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yhat = pd.DataFrame(yhat.reshape(yhat.shape[0], yhat.shape[1]))\n",
    "df_yhat_unscaled = pd.DataFrame(scaler_trend.inverse_transform(df_yhat))\n",
    "df_yhat_unscaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 116.48848208348022\n",
      "MSE 6.644754375838026\n",
      "MSE Percentage 0.24161487295096862\n"
     ]
    }
   ],
   "source": [
    "print('RMSE', mean_squared_error(y_test, df_yhat_unscaled))\n",
    "print('MSE', mean_absolute_error(y_test, df_yhat_unscaled))\n",
    "print('MSE Percentage', mean_absolute_percentage_error(y_test, df_yhat_unscaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.926922</td>\n",
       "      <td>17.437611</td>\n",
       "      <td>20.848406</td>\n",
       "      <td>22.582226</td>\n",
       "      <td>25.439470</td>\n",
       "      <td>28.307318</td>\n",
       "      <td>29.168314</td>\n",
       "      <td>30.377663</td>\n",
       "      <td>29.637938</td>\n",
       "      <td>29.753546</td>\n",
       "      <td>22.283985</td>\n",
       "      <td>22.169481</td>\n",
       "      <td>12.181756</td>\n",
       "      <td>17.798859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.048754</td>\n",
       "      <td>2.017956</td>\n",
       "      <td>4.590934</td>\n",
       "      <td>7.200738</td>\n",
       "      <td>10.703225</td>\n",
       "      <td>13.447351</td>\n",
       "      <td>12.647903</td>\n",
       "      <td>13.198005</td>\n",
       "      <td>10.957108</td>\n",
       "      <td>12.412968</td>\n",
       "      <td>9.666454</td>\n",
       "      <td>10.341459</td>\n",
       "      <td>20.296040</td>\n",
       "      <td>8.848428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.541565</td>\n",
       "      <td>13.772452</td>\n",
       "      <td>14.561196</td>\n",
       "      <td>15.087702</td>\n",
       "      <td>15.603121</td>\n",
       "      <td>16.151459</td>\n",
       "      <td>16.678640</td>\n",
       "      <td>16.857632</td>\n",
       "      <td>17.089212</td>\n",
       "      <td>16.965515</td>\n",
       "      <td>-12.297239</td>\n",
       "      <td>9.457033</td>\n",
       "      <td>-92.449364</td>\n",
       "      <td>-44.677986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.614208</td>\n",
       "      <td>16.191124</td>\n",
       "      <td>17.565979</td>\n",
       "      <td>17.712727</td>\n",
       "      <td>18.229668</td>\n",
       "      <td>18.569991</td>\n",
       "      <td>18.953930</td>\n",
       "      <td>19.198688</td>\n",
       "      <td>19.567220</td>\n",
       "      <td>19.551832</td>\n",
       "      <td>18.345445</td>\n",
       "      <td>17.126960</td>\n",
       "      <td>11.777218</td>\n",
       "      <td>11.870637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.774663</td>\n",
       "      <td>16.528139</td>\n",
       "      <td>18.751877</td>\n",
       "      <td>18.956655</td>\n",
       "      <td>19.970723</td>\n",
       "      <td>20.954962</td>\n",
       "      <td>22.277595</td>\n",
       "      <td>23.640052</td>\n",
       "      <td>25.282697</td>\n",
       "      <td>25.360147</td>\n",
       "      <td>20.538160</td>\n",
       "      <td>18.944288</td>\n",
       "      <td>16.706179</td>\n",
       "      <td>16.764525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.931201</td>\n",
       "      <td>18.329339</td>\n",
       "      <td>23.646703</td>\n",
       "      <td>26.315183</td>\n",
       "      <td>30.408148</td>\n",
       "      <td>37.356490</td>\n",
       "      <td>44.923018</td>\n",
       "      <td>42.605172</td>\n",
       "      <td>41.506823</td>\n",
       "      <td>36.259497</td>\n",
       "      <td>26.083419</td>\n",
       "      <td>22.863872</td>\n",
       "      <td>19.205157</td>\n",
       "      <td>20.806693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.597355</td>\n",
       "      <td>23.326645</td>\n",
       "      <td>32.721523</td>\n",
       "      <td>42.924133</td>\n",
       "      <td>57.333916</td>\n",
       "      <td>57.961208</td>\n",
       "      <td>54.079441</td>\n",
       "      <td>59.044853</td>\n",
       "      <td>50.823250</td>\n",
       "      <td>66.596855</td>\n",
       "      <td>48.254383</td>\n",
       "      <td>65.120560</td>\n",
       "      <td>53.729111</td>\n",
       "      <td>57.624016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  474.000000  474.000000  474.000000  474.000000  474.000000  474.000000   \n",
       "mean    21.926922   17.437611   20.848406   22.582226   25.439470   28.307318   \n",
       "std      6.048754    2.017956    4.590934    7.200738   10.703225   13.447351   \n",
       "min     13.541565   13.772452   14.561196   15.087702   15.603121   16.151459   \n",
       "25%     17.614208   16.191124   17.565979   17.712727   18.229668   18.569991   \n",
       "50%     18.774663   16.528139   18.751877   18.956655   19.970723   20.954962   \n",
       "75%     25.931201   18.329339   23.646703   26.315183   30.408148   37.356490   \n",
       "max     36.597355   23.326645   32.721523   42.924133   57.333916   57.961208   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  474.000000  474.000000  474.000000  474.000000  474.000000  474.000000   \n",
       "mean    29.168314   30.377663   29.637938   29.753546   22.283985   22.169481   \n",
       "std     12.647903   13.198005   10.957108   12.412968    9.666454   10.341459   \n",
       "min     16.678640   16.857632   17.089212   16.965515  -12.297239    9.457033   \n",
       "25%     18.953930   19.198688   19.567220   19.551832   18.345445   17.126960   \n",
       "50%     22.277595   23.640052   25.282697   25.360147   20.538160   18.944288   \n",
       "75%     44.923018   42.605172   41.506823   36.259497   26.083419   22.863872   \n",
       "max     54.079441   59.044853   50.823250   66.596855   48.254383   65.120560   \n",
       "\n",
       "               12          13  \n",
       "count  474.000000  474.000000  \n",
       "mean    12.181756   17.798859  \n",
       "std     20.296040    8.848428  \n",
       "min    -92.449364  -44.677986  \n",
       "25%     11.777218   11.870637  \n",
       "50%     16.706179   16.764525  \n",
       "75%     19.205157   20.806693  \n",
       "max     53.729111   57.624016  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yhat_unscaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Past_2_Days_Close</th>\n",
       "      <th>Past_3_Days_Close</th>\n",
       "      <th>Past_4_Days_Close</th>\n",
       "      <th>Past_5_Days_Close</th>\n",
       "      <th>Past_6_Days_Close</th>\n",
       "      <th>Past_7_Days_Close</th>\n",
       "      <th>Past_8_Days_Close</th>\n",
       "      <th>Past_9_Days_Close</th>\n",
       "      <th>Past_10_Days_Close</th>\n",
       "      <th>Past_11_Days_Close</th>\n",
       "      <th>Past_12_Days_Close</th>\n",
       "      <th>Past_13_Days_Close</th>\n",
       "      <th>Past_14_Days_Close</th>\n",
       "      <th>Past_15_Days_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "      <td>474.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.580640</td>\n",
       "      <td>25.549070</td>\n",
       "      <td>25.515396</td>\n",
       "      <td>25.479232</td>\n",
       "      <td>25.441830</td>\n",
       "      <td>25.403500</td>\n",
       "      <td>25.364597</td>\n",
       "      <td>25.324694</td>\n",
       "      <td>25.287767</td>\n",
       "      <td>25.249920</td>\n",
       "      <td>25.212526</td>\n",
       "      <td>25.180304</td>\n",
       "      <td>25.148545</td>\n",
       "      <td>25.115684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.733458</td>\n",
       "      <td>5.709793</td>\n",
       "      <td>5.682459</td>\n",
       "      <td>5.650912</td>\n",
       "      <td>5.614125</td>\n",
       "      <td>5.575336</td>\n",
       "      <td>5.538773</td>\n",
       "      <td>5.500246</td>\n",
       "      <td>5.463428</td>\n",
       "      <td>5.425122</td>\n",
       "      <td>5.394213</td>\n",
       "      <td>5.367719</td>\n",
       "      <td>5.339752</td>\n",
       "      <td>5.308964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "      <td>17.470224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.399224</td>\n",
       "      <td>21.399224</td>\n",
       "      <td>21.399224</td>\n",
       "      <td>21.399224</td>\n",
       "      <td>21.399224</td>\n",
       "      <td>21.399224</td>\n",
       "      <td>21.379377</td>\n",
       "      <td>21.375377</td>\n",
       "      <td>21.375377</td>\n",
       "      <td>21.375377</td>\n",
       "      <td>21.373235</td>\n",
       "      <td>21.373235</td>\n",
       "      <td>21.373235</td>\n",
       "      <td>21.373235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.657326</td>\n",
       "      <td>23.656199</td>\n",
       "      <td>23.643619</td>\n",
       "      <td>23.606599</td>\n",
       "      <td>23.582159</td>\n",
       "      <td>23.578593</td>\n",
       "      <td>23.575027</td>\n",
       "      <td>23.557829</td>\n",
       "      <td>23.526380</td>\n",
       "      <td>23.512129</td>\n",
       "      <td>23.501442</td>\n",
       "      <td>23.462256</td>\n",
       "      <td>23.430195</td>\n",
       "      <td>23.418983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.041350</td>\n",
       "      <td>28.945153</td>\n",
       "      <td>28.906621</td>\n",
       "      <td>28.833179</td>\n",
       "      <td>28.780056</td>\n",
       "      <td>28.735697</td>\n",
       "      <td>28.689598</td>\n",
       "      <td>28.625674</td>\n",
       "      <td>28.563313</td>\n",
       "      <td>28.549046</td>\n",
       "      <td>28.519201</td>\n",
       "      <td>28.438052</td>\n",
       "      <td>28.400723</td>\n",
       "      <td>28.378229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.156639</td>\n",
       "      <td>40.156639</td>\n",
       "      <td>40.156639</td>\n",
       "      <td>40.156639</td>\n",
       "      <td>40.156639</td>\n",
       "      <td>40.119583</td>\n",
       "      <td>40.119583</td>\n",
       "      <td>40.032852</td>\n",
       "      <td>40.032852</td>\n",
       "      <td>40.032852</td>\n",
       "      <td>40.032852</td>\n",
       "      <td>40.032852</td>\n",
       "      <td>40.032852</td>\n",
       "      <td>40.032852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Past_2_Days_Close  Past_3_Days_Close  Past_4_Days_Close  \\\n",
       "count         474.000000         474.000000         474.000000   \n",
       "mean           25.580640          25.549070          25.515396   \n",
       "std             5.733458           5.709793           5.682459   \n",
       "min            17.470224          17.470224          17.470224   \n",
       "25%            21.399224          21.399224          21.399224   \n",
       "50%            23.657326          23.656199          23.643619   \n",
       "75%            29.041350          28.945153          28.906621   \n",
       "max            40.156639          40.156639          40.156639   \n",
       "\n",
       "       Past_5_Days_Close  Past_6_Days_Close  Past_7_Days_Close  \\\n",
       "count         474.000000         474.000000         474.000000   \n",
       "mean           25.479232          25.441830          25.403500   \n",
       "std             5.650912           5.614125           5.575336   \n",
       "min            17.470224          17.470224          17.470224   \n",
       "25%            21.399224          21.399224          21.399224   \n",
       "50%            23.606599          23.582159          23.578593   \n",
       "75%            28.833179          28.780056          28.735697   \n",
       "max            40.156639          40.156639          40.119583   \n",
       "\n",
       "       Past_8_Days_Close  Past_9_Days_Close  Past_10_Days_Close  \\\n",
       "count         474.000000         474.000000          474.000000   \n",
       "mean           25.364597          25.324694           25.287767   \n",
       "std             5.538773           5.500246            5.463428   \n",
       "min            17.470224          17.470224           17.470224   \n",
       "25%            21.379377          21.375377           21.375377   \n",
       "50%            23.575027          23.557829           23.526380   \n",
       "75%            28.689598          28.625674           28.563313   \n",
       "max            40.119583          40.032852           40.032852   \n",
       "\n",
       "       Past_11_Days_Close  Past_12_Days_Close  Past_13_Days_Close  \\\n",
       "count          474.000000          474.000000          474.000000   \n",
       "mean            25.249920           25.212526           25.180304   \n",
       "std              5.425122            5.394213            5.367719   \n",
       "min             17.470224           17.470224           17.470224   \n",
       "25%             21.375377           21.373235           21.373235   \n",
       "50%             23.512129           23.501442           23.462256   \n",
       "75%             28.549046           28.519201           28.438052   \n",
       "max             40.032852           40.032852           40.032852   \n",
       "\n",
       "       Past_14_Days_Close  Past_15_Days_Close  \n",
       "count          474.000000          474.000000  \n",
       "mean            25.148545           25.115684  \n",
       "std              5.339752            5.308964  \n",
       "min             17.470224           17.470224  \n",
       "25%             21.373235           21.373235  \n",
       "50%             23.430195           23.418983  \n",
       "75%             28.400723           28.378229  \n",
       "max             40.032852           40.032852  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4), dpi=100)\n",
    "#plt.plot(dates, X_test[15].values, label='Real')\n",
    "plt.plot(dates, y_test[frame_size].values, label='HP Filter')\n",
    "plt.plot(dates, df_yhat_unscaled[frame_size].values, label='LSTM Predict')\n",
    "plt.gca().set(title=f'BNB rate from {pd.to_datetime(dates[0]).year}/{pd.to_datetime(dates[0]).month} to {pd.to_datetime(dates[-1]).year}/{pd.to_datetime(dates[-1]).month}', xlabel='Date', ylabel='Rate in dolar')\n",
    "plt.xlabel(\"Position\")\n",
    "plt.ylabel(\"Value ($)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[y_cols]\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = SGDClassifier(random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[18.059635 16.43409  17.89006  18.077581 18.56606  18.906126 19.262169\n 19.509714 19.836903 19.766409 19.45206  19.202967 18.440727 17.007618].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_yhat_unscaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[18.059635 16.43409  17.89006  18.077581 18.56606  18.906126 19.262169\n 19.509714 19.836903 19.766409 19.45206  19.202967 18.440727 17.007618].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "model.predict(df_yhat_unscaled.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
